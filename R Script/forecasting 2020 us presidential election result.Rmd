---
title: "Forecasting 2020 US Presidential Election Result"
subtitle: "Proportion of US Population that would vote for Donald Trump/Joe Biden"
author: "Ke Deng, Yongpeng Hua, Qihui Huang, Qing Wen"
date: "2 November 2020"
output:
  pdf_document: default
  html_document:
    df_print: paged
bibliography: references.bib
---

```{r setup, include=FALSE}
library(tidyverse)

# Loading in the cleaned survey Data
# setwd("C:/Users/10128/Desktop/STA304/Problem Set 3/output")
# survey_data <- read_csv("C:/Users/10128/Desktop/STA304/Problem Set 3/output/survey_data.csv")
survey_data <- read_csv("survey_data.csv")

# Loading in the cleaned census Data
# census_data <- read_csv("C:/Users/10128/Desktop/STA304/Problem Set 3/output/census_data.csv")
census_data <- read_csv("census_data.csv")

```

# Model
The interest for our study is to predict the proportion of people who would vote for Donald Trump along with he proportion of people who would vote for Joe Biden in the upcoming 2020 presidential election. To accomplish this, We would adopt two logistic regression models with the binary response variable indicating people's will whether to vote for Trump/Biden. The model is built using @citeR.

In addition, we are using the multi-regression post-stratification(MRP) technique to arrive at the estimate of our interest. Detailed procedure would be described in the subsection: Post-Stratification. Data sets used are the survey data collected by the Voter Study Group(@citeSurveyData) and the census data(@citeCensusData) collected by the IPUMS USA.

## Model Specifics

As mentioned previously, we would adopt a logistic regression model to find the estimate for the proportion of voters who will vote for our two candidates. We are specifically choosing variables of *employment status*, *gender*, *race*, *household income*, *education level* and *age group*. 

The model is defined by: $$log(\frac{\hat{p}}{1-\hat{p}}) = \hat{\beta_0} + \hat{\beta_1} *x_{employment} +\hat{\beta_2}*x_{gender} +\hat{\beta_3}*x_{race}+\hat{\beta_4}*x_{income} + \hat{\beta_5}*x_{education} + \hat{\beta_6}*x_{age}$$, with each $x_{variable}$ representing corresponding predictor variable, and each $\hat{\beta_i}$ representing the relative change in log odds as the value for the predictor variable increases by an additional unit. Furthermore, $log(\frac{\hat{p}}{1-\hat{p}})$ is the defined log odds rather than probability, so transformation on the log odds would be needed to find the corresponding $\hat{p}$.

```{r, include=FALSE}
attach(survey_data)

# build the model
logitm <- glm(vote_trump~as.factor(employment)+as.factor(gender)+as.factor(race_ethnicity)+as.factor(household_income)+as.factor(education)+as.factor(age_group), family = "binomial")

logitmb <- glm(vote_biden~as.factor(employment)+as.factor(gender)+as.factor(race_ethnicity)+as.factor(household_income)+as.factor(education)+as.factor(age_group), family = "binomial")

detach(survey_data)
```

## Post-Stratification 

Obviously it would be hard to obtain a census data on how each US citizen is going to vote in the election, as the data collecting process would be extremely costly and time-consuming. With the sample data collected which consists of 6,479 observations, we want to form a representative sample to yield a meaningful analysis that could apply well to the general population. The sample size we obtained is really small compared to the total population of US citizens. To compensate for the potential non-representativeness, we want to adopt the post-stratification technique.

We intend to choose the number of variables so that we can obtain a sample as representative as possible meanwhile not over-complicating the model. So we limit the number of variables to 6 but they are all sound categories that could serve to split the population and produce meaningful results. For example, the *gender* and *age group* are both basic information pertaining to a certain individual. Variables like *employment status* and *education level* contain more specific information(i.e. more unique features to define a person's demographic than basic information does). Thus, we use the selected variables to split the cells. 

What post-stratification allows us to do is that we can partition the population data into lots of different demographic cells using the selected variables and use the model built from the survey data to estimate the response variable in each cell(we would be using the logistic model as described in the previous section). Then, by weighing each cell by its relative proportion to the whole population, we could yield an estimate for the total proportion of US citizens voting for either Trump and Biden. The post-stratification estimate is defined as : $${\hat{y}}^{PS} = \frac{\sum{N_j{\hat{y_j}}}}{\sum{N_j}}$$, where $\hat{y_j}$ is the estimate in each cell and $N_j$ is the population size in the jth demographic cell. We will use $\hat{y}^{PS}_{Trump}$ to denote the proportion estimate for voting for Trump and $\hat{y}^{PS}_{Biden}$ to denote the proportion estimate for voting for Biden.


```{r, include=FALSE}

# Find estimate for log odds for each cell
census_data$logodds_estimate <-
  logitm %>%
  predict(newdata = census_data)

# convert the log odds into probabilities
census_data$estimate <-
  exp(census_data$logodds_estimate)/(1+exp(census_data$logodds_estimate))

# yield estimates for each cell than aggregate to find the final estimate
yps <- census_data %>%
  mutate(alp_predict_prop = estimate*n) %>%
  summarise(alp_predict = sum(alp_predict_prop)/sum(n))
yps

### results for voting Biden
census_data$logodds_estimate_b <-
  logitmb %>%
  predict(newdata = census_data)

# convert the log odds into probabilities
census_data$estimate_b <-
  exp(census_data$logodds_estimate_b)/(1+exp(census_data$logodds_estimate_b))

# yield estimates for each cell than aggregate to find the final estimate
yps_b <- census_data %>%
  mutate(alp_predict_prop_b = estimate_b*n) %>%
  summarise(alp_predict_b = sum(alp_predict_prop_b)/sum(n))
yps_b
```


## Notes on Data Cleaning Process
We create two binary variables in the survey data, namely *vote_trump* and *vote_biden* in the survey data. Taking *vote_trump* for instance, we mutates all the responses for *vote_2020* that is "Donald Trump" to have the value 1, and 0 otherwise. The same procedure applied to *vote_biden*. One thing to notice is that in the *vote_2020*, there are responses of "I am not sure/don't know", which we also signed a value 0.

In order to let the model built on the survey data to successfully yield desired estimates, we need to clean up both the survey data and census data so that each variable we choose contains the same levels of categorical values. For instance, we would like to have the *gender* variable in both the survey and census data to have two levels, namely *male* and *female*. So we would need to ensure that this is indeed the case in both data sets, so the model built from the survey data is be able to predict the estimates based on the input of census data. 

Some of the cleaning process worths mentioning are:

1. Considering *education* as a possible factor, we combine some of the small groups(population) into larger groups(sample) instead of keeping all the small groups. The reasons are: keeping the consistency between *census* data and *survey* data, so that they have the same number of groups in *education*; the groups in *census* are over-detailed, and some groups are repeated which means they represent the similar groups, we can combine them into a large group. In this case, we classify all 42 groups from *census* dataset into 11 large groups in *survey* dataset. For instance, **associate's degree, type not specified**, **associate's degree, occupational program** and **associate's degree, academic program** all goes into the **Associate Degree** group in *survey* dataset.

2. Considering *race* as a possible factor, voters with different races may affect their voting decisions. We combine some small groups(sample) of variables into larger groups(population). The reasons are: keeping the consistency between *census* data and *survey* data, so that they have the same number of groups in *race*; the groups(*race_ethnicity*) in *survey* are over-detailed, and some groups of races can be included in a larger group. In this case, the original 15 groups are classified to 7 groups, which are *white*, *black/african american/negro*, *american indian or alaska native*, *chinese*, *japanese*, *other asian or pacific islander*, and *other race, nec*. In addition, the variable *race_ethnicity* is renamed to *race* in *census* dataset and also in the model. 

3. Considering *age_group* as a possible factor, people at different ages with different experiences might affect their voting choices. Since age_group is a variable mutated from ages, that is considered to be a numeric variable, can be directly mutated. In the sample data, it only records age groups that are over 18 years old. However, the population data consists of those that are under 18 and are not eligible to vote, which is being filtered out for the model.

4. Considering *employment* as a possible factor, people with different careers and different employment statuses are recorded down. We have combined the more specific divisions (sample) into a more general division (population), as we would like to keep the consistency between *census* and *survey* data so that the groups are the same for both in *employment*. In the sample data, the people with jobs are considered to be employed, including groups that are *Part-time employed*, *Full-time employed*, *Self-employed*. The other general division is people that are *not in labor force*, which in the sample are groups that are *Homemaker*, *Permanently disabled*, *Retired*, and *Student*. People who are *Unemployed or temporarily on layoff* are considered to be *unemployed*. One note is that those that have employment noted as *Other*, are grouped *n/a*. In the population data, when people under 18 years old are being filtered out, we have found out that those that have employment as *n/a* are those that are under 18 years old, so it does not cause any trouble in the model.



# Results

Note: Here we are showing the first few rows of the output. For complete table of output, please refer to the Appendix for table 1 and table 2.

Table 1: Logstic regression output for predicting proportion of votes for Donald Trump

```{r, message=FALSE, echo=FALSE}
# model output in a tidy table
trump_result <- broom::tidy(logitm)
head(trump_result)
yps
```

In the model output for voting Trump prediction, we get the coefficients for the regression equation, including the parameters of interest like intercepts and slopes for each factor). Estimated intercept for regression equation here is -0.1809. Estimated values for slope parameters vary based on different fields and different cells. Male increases the log odds while female does not have contributions in this cell. Also, unemployed citizens lowered the result as well. In race and ethnicity fields, races except white have lowered the expected change in log odds of Trump winning the election; other factors like education and employment have lowered the log odds as well. People from different age groups contribute to the log odds of Trump winning the election greater or lesser. One thing is worth mentioning is that not all classes contribute to the expected log odds of winning, income of a family only between 200,000 to 249,999 U.S. dollars, 250,000 U.S. dollars above contribute, the others somewhat decrease the log odds. Finally, by extracting the probability from log odds and aggregating estimates from each cell. The estimated probability of Trump winning the election is 0.3897. 


Table 2: Logistic regression output for predicting proportion of votes for Joe Biden

```{r}
biden_result <- broom::tidy(logitmb)
head(biden_result)
yps_b
```

In the logistic model output for voting Biden prediction, we use exactly the same factors to predict. The estimated intercept for the regression model is -0.5952. Contrary to what we got in predicting Trump's winning probability, unemployed/not in labor citizens rises log odds output, and males decline it. Moreover, the race factor contributes but age groups factor decreases the output. College degree and Master degree is likely to increase the odds. For different income groups, only a few groups may lower the odds like income ranging from 175,000 to 199,999 U.S. dollars and above 250,000 U.S. dollars. The estimated probability of voting for Biden more than Trump a little, which is 0.4062.

The P-value for each factors in both logistic models are less than 0.005.


# Discussion

## Summary
In this study, we focus on the MRP technique to produce an estimate for the proportion of voters intending to vote for Donald Trump or for Joe Biden in the upcoming 2020 presidential election. We start off by reading in and cleaning the survey and census data to ensure that the variables in both data sets contain the same sets of levels for our model to yield prediction. After that, we fit in two logistic regression models to the survey data with the predictor and response variables identified previously. Lastly, we apply this model to the census data which already consists of splitted demographic cells to yield estimates for the proportion of voters in each cell and aggregate our calculation to the population level to obtain the final estimate. A quick glimpse of what the cells look like eventually is as follows:

```{r, message=FALSE, echo=FALSE, warning=FALSE}
head(census_data)
```
We finally arrived at two estimates for the proportion of voters: $\hat{y}^{PS}_{Trump} = 0.39$ and $\hat{y}^{PS}_{Biden} = 0.41$.

## Conclusion

discuss conclusions drawn from the results. Make sure to elaborate and connect your analysis to the goal of the study.

## Weaknesses

One weakness that can be identified in our model is that due to the unmatch between the census data and the sample data, many variables that contain detailed information are being merged into smaller and more general divisions, which can cause a loss of information. For example, there are two variables in the census data that recorded the detailed employment status and more general employment status. We chose the more general variable due to the mismatch between the detailed employment status in the census and the sample data. 

## Next Steps

Going from the weakness section, the merging of groups within variables can make the model less informative. The next step to make a better model is to see if there are data sets (sample data and census data) that have variables that include more similar group divisions than the currently used data sets.


# Appendix
Table 1: Complete result for table 1 in the result session
```{r, echo=FALSE, message=FALSE}
print(trump_result, n = 50)
```

Table 2: Complete result for table 2 in the result session
```{r}
print(biden_result, n = 50)
```



