---
title: "Forecasting 2020 US Presidential Election Result"
subtitle: "Proportion of US Population that would vote for Donald Trump/Joe Biden"
author: "Ke Deng, Yongpeng Hua, Qihui Huang, Qing Wen"
date: "2 November 2020"
output:
  html_document:
    df_print: paged
  pdf_document: default
bibliography: references.bib
---

```{r setup, include=FALSE}
library(tidyverse)

# Loading in the cleaned survey Data
# setwd("C:/Users/10128/Desktop/STA304/Problem Set 3/output")
# survey_data <- read_csv("C:/Users/10128/Desktop/STA304/Problem Set 3/output/survey_data.csv")
survey_data <- read_csv("survey_data.csv")

# Loading in the cleaned census Data
# census_data <- read_csv("C:/Users/10128/Desktop/STA304/Problem Set 3/output/census_data.csv")
census_data <- read_csv("census_data.csv")

```

# Model
The interest for our study is to predict the proportion of people who would vote for Donald Trump along with he proportion of people who would vote for Joe Biden in the upcoming 2020 presidential election. To accomplish this, We would adopt two logistic regression models with the binary response variable indicating people's will whether to vote for Trump/Biden. The model is built using @citeR.

In addition, we are using the multi-regression post-stratification(MRP) technique to arrive at the estimate of our interest. Detailed procedure would be described in the subsection: Post-Stratification. Data sets used are the survey data collected by the Voter Study Group(@citeSurveyData) and the census data(@citeCensusData) collected by the IPUMS USA.

## Model Specifics

As mentioned previously, we would adopt a logistic regression model to find the estimate for the proportion of voters who will vote for our two candidates. We are specifically choosing variables of *employment status*, *gender*, *race*, *household income*, *education level* and *age group*. 

The model is defined by: $$log(\frac{\hat{p}}{1-\hat{p}}) = \hat{\beta_0} + \hat{\beta_1} *x_{employment} +\hat{\beta_2}*x_{gender} +\hat{\beta_3}*x_{race}+\hat{\beta_4}*x_{income} + \hat{\beta_5}*x_{education} + \hat{\beta_6}*x_{age}$$, with each $x_{variable}$ representing corresponding predictor variable, and each $\hat{\beta_i}$ representing the relative change in log odds as the value for the predictor variable increases by an additional unit. Furthermore, $log(\frac{\hat{p}}{1-\hat{p}})$ is the defined log odds rather than probability, so transformation on the log odds would be needed to find the corresponding $\hat{p}$.

```{r, include=FALSE}
attach(survey_data)

# build the model
logitm <- glm(vote_trump~as.factor(employment)+as.factor(gender)+as.factor(race_ethnicity)+as.factor(household_income)+as.factor(education)+as.factor(age_group), family = "binomial")

logitmb <- glm(vote_biden~as.factor(employment)+as.factor(gender)+as.factor(race_ethnicity)+as.factor(household_income)+as.factor(education)+as.factor(age_group), family = "binomial")

detach(survey_data)
```

## Post-Stratification 

Obviously it would be hard to obtain a census data on how each US resident is going to vote in the election, as the data collecting process would be extremely costly and time-consuming. With the sample data collected which consists of 6,479 observations, we want to form a representative sample to yield a meaningful analysis that could apply well to the general population. The sample size we obtained is really small compared to the total population of US citizens. To compensate for the potential non-representativeness, we want to adopt the post-stratification technique.

We intend to choose the number of variables so that we can obtain a sample as representative as possible meanwhile not over-complicating the model. So we limit the number of variables to 6 but they are all good enough to represent the demographics that could serve to split the population and produce meaningful results. For example, the *gender* and *age group* are both basic information pertaining to a certain individual. Variables like *employment status* and *education level* contain information more specific(i.e. more unique features to define a person's demographic than basic information does). Thus, we use the selected variables to split the cells. 

What post-stratification allows us to do is that we can partition the population data into lots of different demographic cells and use the model built from the survey data to estimate the response variable in each cell(we would be using the logistic model as described in the previous section). Then, by weighing each cell by its relative proportion to the whole population, we could yield an estimate for our ultimate goal. The post-stratification estimate is defined as : $${\hat{y}}^{PS} = \frac{\sum{N_j{\hat{y_j}}}}{\sum{N_j}}$$ , where $\hat{y_j}$ is the estimate in each cell and $N_j$ is the population size in the jth demographic cell.


```{r, include=FALSE}

# Find estimate for log odds for each cell
census_data$logodds_estimate <-
  logitm %>%
  predict(newdata = census_data)

# convert the log odds into probabilities
census_data$estimate <-
  exp(census_data$logodds_estimate)/(1+exp(census_data$logodds_estimate))

# yield estimates for each cell than aggregate to find the final estimate
yps <- census_data %>%
  mutate(alp_predict_prop = estimate*n) %>%
  summarise(alp_predict = sum(alp_predict_prop)/sum(n))


### results for voting Biden
census_data$logodds_estimate_b <-
  logitmb %>%
  predict(newdata = census_data)

# convert the log odds into probabilities
census_data$estimate_b <-
  exp(census_data$logodds_estimate_b)/(1+exp(census_data$logodds_estimate_b))

# yield estimates for each cell than aggregate to find the final estimate
yps_b <- census_data %>%
  mutate(alp_predict_prop_b = estimate_b*n) %>%
  summarise(alp_predict_b = sum(alp_predict_prop_b)/sum(n))

```


## Notes on Data Cleaning Process
In order to let the model built on the survey data to successfully yield desired estimates, we need to clean up both the survey data and census data so that each variable we choose contains the same levels of categorical values. For instance, we would like to have the *gender* variable in both the survey and census data to have two levels, namely *male* and *female*. So we would need to ensure that this is indeed the case in both data sets, so the model built from the survey data is be able to predict the estimates based on the input of census data. 

Some of the cleaning process worths mentioning are:

1. Considering *education* as a possible factor, we combine some of the small groups(population) into larger groups(sample) instead of keeping all the small groups. The reasons are: keeping the consistency between *census* data and *survey* data, so that they have the same number of groups in *education*; the groups in *census* are over-detailed, and some groups are repeated which means they represent the similar groups, we can combine them into a large group. In this case, we classify all 42 groups from *census* dataset into 11 large groups in *survey* dataset. For instance, **associate's degree, type not specified**, **associate's degree, occupational program** and **associate's degree, academic program** all goes into the **Associate Degree** group in *survey* dataset.

2. 

3.



# Results

```{r, message=FALSE, echo=FALSE}
# model output in a tidy table
broom::tidy(logitm)
broom::tidy(logitmb)
yps
yps_b
```

Here you will include all results. This includes descriptive statistics, graphs, figures, tables, and model results. Please ensure that everything is well formatted and in a report style. You must also provide an explanation of the results in this section. 

Please ensure that everything is well labelled. So if you have multiple histograms and plots, calling them Figure 1, 2, 3, etc. and referencing them as Figure 1, Figure 2, etc. in your report will be expected. The reader should not get lost in a sea of information. Make sure to have the results be clean, well formatted and digestible.

# Discussion

## Summary
In this study, we focus on the MRP technique to produce an estimate for the proportion of voters intending to vote for Donald Trump in the upcoming 2020 presidential election. We start off by reading in and cleaning the survey and census data to ensure that the variables in both data sets contain the same sets of levels for out model to yield prediction. After that, we fit in a logistic regression model to the survey data with the predictor and response variables identified previously. Lastly, we apply this model to the census data which already consists of splitted demographic cells to yield estimate for the proportion of voters in each cell and aggregate our calculation to the population level to obtain the final estimate. A quick glimpse of what the cells look like eventually is as follows:

```{r, message=FALSE, echo=FALSE, warning=FALSE}
# kable(census_data)
head(census_data)
```

## Conclusion

discuss conclusions drawn from the results. Make sure to elaborate and connect your analysis to the goal of the study.

## Weaknesses

Here we discuss weaknesses of the study, data, analysis, etc. You can also discuss areas for improvement.

## Next Steps

Here you discuss subsequent work to be done after this report. This can include next steps in terms of statistical analysis (perhaps there is a more efficient algorithm available, or perhaps there is a caveat in the data that would allow for some new technique). Future steps should also be specified in terms of the study setting (eg. including a follow-up survey on something, or a subsequent study that would complement the conclusions of your report).


# References